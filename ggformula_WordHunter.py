# app_streamlit_suffix_toggle_translate_parallel.py
import streamlit as st
import pandas as pd
from io import BytesIO
from pathlib import Path
from deep_translator import GoogleTranslator
from nltk.corpus import wordnet
import nltk
from concurrent.futures import ThreadPoolExecutor

# Download WordNet data (only once)
nltk.download('wordnet')
nltk.download('omw-1.4')

# Streamlit page config
st.set_page_config(page_title="Word Suffix Finder", layout="wide")
CACHE_DIR = Path("data")
CACHE_DIR.mkdir(exist_ok=True)

# POS mapping
POS_MAP = {
    'n': 'рокрпЖропро░рпНроЪрпНроЪрпКро▓рпН',
    'v': 'ро╡ро┐ройрпИроЪрпНроЪрпКро▓рпН',
    'a': 'ро╡ро┐ро│ро┐рокрпНрокрпЖропро░рпН',
    's': 'ро╡ро┐ро│ро┐рокрпНрокрпЖропро░рпН (роЪро╛роЯрпНроЯро┐ро▓рпИроЯрпН)',
    'r': 'ро╡ро┐ройрпИропроЯрпИ'
}

# Cached translation
@st.cache_data(show_spinner=False)
def translate_to_tamil(text: str):
    try:
        return GoogleTranslator(source='auto', target='ta').translate(text)
    except:
        return ""

# Parallel translation wrapper
def translate_list_parallel(texts, max_workers=10):
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(translate_to_tamil, texts))
    return results

# Find matching words
def find_matches(words, suffix, before_letters):
    suf = suffix.lower()
    matched = []
    for w in words:
        if w.lower().endswith(suf):
            if before_letters == 0 or len(w) - len(suf) == before_letters:
                matched.append(w)
    matched.sort(key=len)
    return matched

# Highlight suffix in word
def make_highlight_html(word, suf):
    if suf and word.lower().endswith(suf.lower()):
        p = word[:-len(suf)]
        s = word[-len(suf):]
        return f"<div style='font-size:20px; padding:6px;'><span>{p}</span><span style='color:#e53935; font-weight:700'>{s}</span></div>"
    else:
        return f"<div style='font-size:20px; padding:6px;'>{word}</div>"

# CSS Styling
st.markdown("""
<style>
.app-header {background: linear-gradient(90deg,#a1c4fd,#c2e9fb); padding: 12px; border-radius: 8px;}
</style>
""", unsafe_allow_html=True)

# Header
st.markdown("<div class='app-header'><h1 style='margin:0'>роХро▓рпНро╡ро┐ ро╡ро┐родрпИроХро│рпН роорпБро│рпИроХрпНроХрпБроорпН роЗроЯроорпН</h1><small>Suffix роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓рпН роЪрпКро▒рпНроХро│рпИродрпН родрпЗроЯро╡рпБроорпН, роЕро░рпНродрпНродроЩрпНроХро│рпБроЯройрпН рокро╛ро░рпНроХрпНроХро╡рпБроорпН</small></div>", unsafe_allow_html=True)

# Sidebar settings
with st.sidebar:
    st.header("ЁЯФз родрпЗроЯрпБродро▓рпИ роОро│ро┐роорпИропро╛роХрпНроХрпБ")
    before_letters = st.number_input("роЗро▒рпБродро┐роХрпНроХрпБ роорпБройрпН роЙро│рпНро│ роОро┤рпБродрпНродрпБроХро│рпН (0 роОройрпНро▒ро╛ро▓рпН роОроирпНродро╡рпКро░рпБ роОрогрпНрогрпБроорпН)", min_value=0, step=1, value=0)
    lang_choice = st.radio("роЕро░рпНродрпНродроорпН роХро╛рогрпНрокро┐роХрпНроХ:", ["English Only", "Tamil Only", "English + Tamil"])
    max_threads = st.slider("Translation Threads (ро╡рпЗроХ роХроЯрпНроЯрпБрокрпНрокро╛роЯрпБ)", min_value=2, max_value=20, value=10)

# Load all WordNet lemma names
all_words = sorted(set(wordnet.all_lemma_names()), key=lambda x: (len(x), x.lower()))

# Layout
col1, col2 = st.columns([1,2])

with col1:
    st.subheader("ЁЯФО роЪрпКро▒рпНроХро│рпИродрпН родрпЗроЯрпБ")
    suffix_input = st.text_input("Suffix (роЙродро╛: 'ight')", value="ight")
    matches = find_matches(all_words, suffix_input, before_letters)

    st.markdown(f"**роХро┐роЯрпИродрпНрод роорпКродрпНрод роЪрпКро▒рпНроХро│рпН:** {len(matches)}")

    # роЗроирпНродроХрпН div-роХрпНроХрпБро│рпН родро╛ройрпН ро╕рпНроХрпНро░рпЛро▓ро┐роЩрпН ро╡роЪродро┐ роЙро│рпНро│родрпБ.
    # max-height:520px; - роЕродро┐роХрокроЯрпНроЪ роЙропро░роорпН
    # overflow-y:auto; - роЙропро░роорпН родро╛рогрпНроЯрпБроорпНрокрпЛродрпБ родро╛ройро╛роХро╡рпЗ ро╕рпНроХрпНро░рпЛро▓ро┐роЩрпН рокроЯрпНроЯро┐ ро╡ро░рпБроорпН
    st.markdown("<div style='max-height:520px; overflow-y:auto; padding:6px; background:#fff8e1; border-radius:6px;'>", unsafe_allow_html=True)
    if matches:
        for w in matches:
            st.markdown(make_highlight_html(w, suffix_input), unsafe_allow_html=True)
    else:
        st.info("роорпБроЯро┐ро╡рпБроХро│рпН роОродрпБро╡рпБроорпН роЗро▓рпНро▓рпИ.")
    st.markdown("</div>", unsafe_allow_html=True)

with col2:
    st.subheader("ЁЯУШроЪрпКро▒рпНроХро│ро┐ройрпН рокрпКро░рпБро│рпНроХро│рпН")

    if matches:
        data_rows = []
        for word in matches:
            syns = wordnet.synsets(word)
            if not syns:
                data_rows.append({"роЪрпКро▓рпН": word, "роЪрпКро▓рпН ро╡роХрпИ": "-", "роЖроЩрпНроХро┐ро▓роорпН": "-", "родрооро┐ро┤рпН": "-"})
            else:
                for syn in syns:
                    eng = syn.definition()
                    data_rows.append({
                        "роЪрпКро▓рпН": word,
                        "роЪрпКро▓рпН ро╡роХрпИ": POS_MAP.get(syn.pos(), "рокрпЖропро░рпНроЪрпНроЪрпКро▓рпН"),
                        "роЖроЩрпНроХро┐ро▓роорпН": eng
                    })

        df_export = pd.DataFrame(data_rows)

        # Translate only if Tamil is needed
        if lang_choice != "English Only":
            tamil_list = translate_list_parallel(df_export["роЖроЩрпНроХро┐ро▓роорпН"].tolist(), max_workers=max_threads)
            df_export["родрооро┐ро┤рпН"] = tamil_list
        else:
            df_export["родрооро┐ро┤рпН"] = "-"

        # Filter columns
        if lang_choice == "English Only":
            df_view = df_export[["роЪрпКро▓рпН", "роЪрпКро▓рпН ро╡роХрпИ", "роЖроЩрпНроХро┐ро▓роорпН"]]
        elif lang_choice == "Tamil Only":
            df_view = df_export[["роЪрпКро▓рпН", "роЪрпКро▓рпН ро╡роХрпИ", "родрооро┐ро┤рпН"]]
        else:
            df_view = df_export

        # Excel download
        towrite = BytesIO()
        with pd.ExcelWriter(towrite, engine="xlsxwriter") as writer:
            df_export.to_excel(writer, index=False, sheet_name="Meanings")
        towrite.seek(0)
        st.download_button("ЁЯУе EXCEL SHEET-роЖроХ рокродро┐ро╡ро┐ро▒роХрпНроХрпБ", towrite, file_name="all_meanings.xlsx")

        st.dataframe(df_view)
    else:
        st.info("роорпБроЯро┐ро╡рпБроХро│рпН роОродрпБро╡рпБроорпН роЗро▓рпНро▓рпИ.")





